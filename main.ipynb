{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4558742,"sourceType":"datasetVersion","datasetId":2660745}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport os\nfrom tensorflow.keras import layers\nimport string","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.478792Z","iopub.execute_input":"2025-11-08T10:56:15.479831Z","iopub.status.idle":"2025-11-08T10:56:15.483786Z","shell.execute_reply.started":"2025-11-08T10:56:15.479799Z","shell.execute_reply":"2025-11-08T10:56:15.483162Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"BATCH_SIZE = 128\nNUM_HEADS = 8\nNUM_BLOCKS = 4\nEMBED_DIM = 512\nDENSE_DIM = 2048\nDROPOUT_RATE = 0.2\nCHUNK_LENGTH = 150","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.484946Z","iopub.execute_input":"2025-11-08T10:56:15.485246Z","iopub.status.idle":"2025-11-08T10:56:15.496591Z","shell.execute_reply.started":"2025-11-08T10:56:15.485228Z","shell.execute_reply":"2025-11-08T10:56:15.495848Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/the-bards-best-a-character-modeling-dataset/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.497750Z","iopub.execute_input":"2025-11-08T10:56:15.498018Z","iopub.status.idle":"2025-11-08T10:56:15.525333Z","shell.execute_reply.started":"2025-11-08T10:56:15.498001Z","shell.execute_reply":"2025-11-08T10:56:15.524743Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"text = df.values[0][0]\ntext = re.sub(r'\\s+', ' ', str(text)).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.526054Z","iopub.execute_input":"2025-11-08T10:56:15.526541Z","iopub.status.idle":"2025-11-08T10:56:15.592025Z","shell.execute_reply.started":"2025-11-08T10:56:15.526522Z","shell.execute_reply":"2025-11-08T10:56:15.591333Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import re\n\nwords = text.split()\n\n# Count unique words\nunique_words = set(words)\nprint(f\"Total words: {len(words)}\")\nprint(f\"Unique words: {len(unique_words)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.593871Z","iopub.execute_input":"2025-11-08T10:56:15.594071Z","iopub.status.idle":"2025-11-08T10:56:15.631847Z","shell.execute_reply.started":"2025-11-08T10:56:15.594056Z","shell.execute_reply":"2025-11-08T10:56:15.631117Z"}},"outputs":[{"name":"stdout","text":"Total words: 182499\nUnique words: 23841\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def chunk_text_by_words(text, max_words, stride=None):\n    words = text.split()\n    if stride is None:\n        stride = max_words // 2\n    chunks = []\n    for i in range(0, len(words) - max_words, stride):\n        chunk = ' '.join(words[i:i + max_words])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.632512Z","iopub.execute_input":"2025-11-08T10:56:15.632698Z","iopub.status.idle":"2025-11-08T10:56:15.644711Z","shell.execute_reply.started":"2025-11-08T10:56:15.632684Z","shell.execute_reply":"2025-11-08T10:56:15.644076Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"chunks = chunk_text_by_words(text, CHUNK_LENGTH+1, 15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.645561Z","iopub.execute_input":"2025-11-08T10:56:15.645872Z","iopub.status.idle":"2025-11-08T10:56:15.709920Z","shell.execute_reply.started":"2025-11-08T10:56:15.645850Z","shell.execute_reply":"2025-11-08T10:56:15.709370Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print(np.shape(chunks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.710858Z","iopub.execute_input":"2025-11-08T10:56:15.711056Z","iopub.status.idle":"2025-11-08T10:56:15.762145Z","shell.execute_reply.started":"2025-11-08T10:56:15.711040Z","shell.execute_reply":"2025-11-08T10:56:15.761153Z"}},"outputs":[{"name":"stdout","text":"(12157,)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"strip_chars = string.punctuation + \"¿\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(\n        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n\nvocab_size = 12050\nsequence_length = CHUNK_LENGTH+1\n\nvectorizer = layers.TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n    standardize=custom_standardization\n)\n\nvectorizer.adapt(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:15.763247Z","iopub.execute_input":"2025-11-08T10:56:15.763585Z","iopub.status.idle":"2025-11-08T10:56:16.315266Z","shell.execute_reply.started":"2025-11-08T10:56:15.763557Z","shell.execute_reply":"2025-11-08T10:56:16.314362Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"vocab = vectorizer.get_vocabulary()\nprint(\"Total unique tokens in vocabulary:\", len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.318336Z","iopub.execute_input":"2025-11-08T10:56:16.318630Z","iopub.status.idle":"2025-11-08T10:56:16.353715Z","shell.execute_reply.started":"2025-11-08T10:56:16.318604Z","shell.execute_reply":"2025-11-08T10:56:16.353025Z"}},"outputs":[{"name":"stdout","text":"Total unique tokens in vocabulary: 12050\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"def make_dataset(chunks):\n    tokens = vectorizer(chunks)\n    tokens_inp = tokens[:,:CHUNK_LENGTH]\n    tokens_out = tokens[:,1:]\n    ds = tf.data.Dataset.from_tensor_slices((tokens_inp,tokens_out))\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.shuffle(1024).prefetch(16).cache()\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.354689Z","iopub.execute_input":"2025-11-08T10:56:16.354928Z","iopub.status.idle":"2025-11-08T10:56:16.359002Z","shell.execute_reply.started":"2025-11-08T10:56:16.354902Z","shell.execute_reply":"2025-11-08T10:56:16.358133Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"ds = make_dataset(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.359855Z","iopub.execute_input":"2025-11-08T10:56:16.360432Z","iopub.status.idle":"2025-11-08T10:56:16.954230Z","shell.execute_reply.started":"2025-11-08T10:56:16.360408Z","shell.execute_reply":"2025-11-08T10:56:16.953611Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self, sequence_length, vocab_size, output_dim):\n        super().__init__()\n        self.positional_embedding = tf.keras.layers.Embedding(input_dim = sequence_length, output_dim = output_dim, mask_zero=False)\n        self.token_embedding = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim= output_dim, mask_zero=True)\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embedding(inputs)\n        embedded_positions = self.positional_embedding(positions)\n        return embedded_tokens + embedded_positions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.955043Z","iopub.execute_input":"2025-11-08T10:56:16.955342Z","iopub.status.idle":"2025-11-08T10:56:16.960794Z","shell.execute_reply.started":"2025-11-08T10:56:16.955319Z","shell.execute_reply":"2025-11-08T10:56:16.960071Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"class TransformerDecoder(tf.keras.layers.Layer):\n    def __init__(self, num_heads, embed_dim, dense_dim, dropout_rate):\n        super().__init__()\n        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n                                                           key_dim=embed_dim//num_heads)\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n        self.dense_proj = tf.keras.models.Sequential([\n            tf.keras.layers.Dense(dense_dim, activation='gelu'),\n            tf.keras.layers.Dense(embed_dim)\n        ])\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n    def call(self, inputs):\n        attn_out = self.attention(query=inputs,\n                            key=inputs,\n                            value=inputs,\n                            use_causal_mask=True)\n        norm1_out = self.layernorm1(attn_out+inputs)\n        drop1_out = self.dropout1(norm1_out)\n        dense_proj_out = self.dense_proj(drop1_out)\n        norm2_out = self.layernorm2(drop1_out+dense_proj_out)\n        drop2_out = self.dropout2(norm2_out)\n        return drop2_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.961420Z","iopub.execute_input":"2025-11-08T10:56:16.961652Z","iopub.status.idle":"2025-11-08T10:56:16.976229Z","shell.execute_reply.started":"2025-11-08T10:56:16.961628Z","shell.execute_reply":"2025-11-08T10:56:16.975656Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"inputs = tf.keras.layers.Input(shape=(None,))\nembeddings = PositionalEmbedding(sequence_length, vocab_size, EMBED_DIM)(inputs)\nx = embeddings\nfor layer in range(NUM_BLOCKS):\n    x = TransformerDecoder(NUM_HEADS, EMBED_DIM, DENSE_DIM, DROPOUT_RATE)(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutput = tf.keras.layers.Dense(vocab_size, activation='linear', kernel_initializer='glorot_uniform')(x)\ntransformer = tf.keras.models.Model(inputs, output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:16.976949Z","iopub.execute_input":"2025-11-08T10:56:16.977223Z","iopub.status.idle":"2025-11-08T10:56:18.051072Z","shell.execute_reply.started":"2025-11-08T10:56:16.977205Z","shell.execute_reply":"2025-11-08T10:56:18.050527Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"transformer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:18.051879Z","iopub.execute_input":"2025-11-08T10:56:18.052535Z","iopub.status.idle":"2025-11-08T10:56:18.070168Z","shell.execute_reply.started":"2025-11-08T10:56:18.052508Z","shell.execute_reply":"2025-11-08T10:56:18.069616Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_11\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m6,246,912\u001b[0m │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,152,384\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,152,384\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,152,384\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,152,384\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12050\u001b[0m)    │     \u001b[38;5;34m6,181,650\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,246,912</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,152,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,152,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,152,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,152,384</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12050</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,181,650</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,038,098\u001b[0m (95.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,038,098</span> (95.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,038,098\u001b[0m (95.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,038,098</span> (95.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\ndef perplexity(y_true, y_pred):\n    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n    return K.exp(K.mean(cross_entropy))\n\ntransformer.compile(loss = loss_fn,\n                    metrics = ['accuracy', perplexity],\n                    optimizer=opt)\ntransformer.fit(ds, epochs = 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T10:56:18.070760Z","iopub.execute_input":"2025-11-08T10:56:18.070944Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1762599395.367847      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1762599395.367984      99 assert_op.cc:38] Ignoring Assert operator SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m63/95\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 365ms/step - accuracy: 0.0257 - loss: 7.5184 - perplexity: 2873.5398","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1762599432.217085      96 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1762599432.217170      96 assert_op.cc:38] Ignoring Assert operator SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 510ms/step - accuracy: 0.0265 - loss: 7.3784 - perplexity: 2388.6340\nEpoch 2/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 366ms/step - accuracy: 0.0292 - loss: 6.8409 - perplexity: 940.9731\nEpoch 3/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0290 - loss: 6.8076 - perplexity: 909.0232\nEpoch 4/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 369ms/step - accuracy: 0.0299 - loss: 6.7864 - perplexity: 889.9170\nEpoch 5/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 369ms/step - accuracy: 0.0302 - loss: 6.7770 - perplexity: 881.4621\nEpoch 6/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 369ms/step - accuracy: 0.0304 - loss: 6.7746 - perplexity: 880.1837\nEpoch 7/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 369ms/step - accuracy: 0.0302 - loss: 6.7905 - perplexity: 893.8193\nEpoch 8/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0309 - loss: 6.8053 - perplexity: 907.2952\nEpoch 9/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0310 - loss: 6.8017 - perplexity: 903.9184\nEpoch 10/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0312 - loss: 6.7983 - perplexity: 900.6302\nEpoch 11/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0313 - loss: 6.7921 - perplexity: 895.0020\nEpoch 12/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0314 - loss: 6.7855 - perplexity: 889.1207\nEpoch 13/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7804 - perplexity: 884.5735\nEpoch 14/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0316 - loss: 6.7772 - perplexity: 881.8196\nEpoch 15/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7739 - perplexity: 878.8306\nEpoch 16/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7717 - perplexity: 876.9781\nEpoch 17/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0314 - loss: 6.7696 - perplexity: 875.0942\nEpoch 18/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7683 - perplexity: 873.9728\nEpoch 19/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7671 - perplexity: 872.8511\nEpoch 20/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 368ms/step - accuracy: 0.0315 - loss: 6.7658 - perplexity: 871.7634\nEpoch 21/500\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 367ms/step - accuracy: 0.0315 - loss: 6.7648 - perplexity: 870.9402\nEpoch 22/500\n\u001b[1m38/95\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 368ms/step - accuracy: 0.0311 - loss: 6.7451 - perplexity: 852.2613","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\ndef sample_with_temperature(preds, temperature=1.0):\n    preds = np.asarray(preds).astype(\"float64\")\n    preds = np.log(preds + 1e-9) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    return np.random.choice(len(preds), p=preds)\n\ndef generate_text(prompt, max_length=50, temperature=0.8):\n    for _ in range(max_length):\n        tokenized = vectorizer([prompt])\n        preds = transformer(tokenized)\n        preds = tf.nn.softmax(preds[0, -1, :]).numpy()\n        next_id = sample_with_temperature(preds, temperature)\n        print(next_id)\n        next_word = vectorizer.get_vocabulary()[next_id]\n        prompt += \" \" + next_word\n        if next_word == \"eos\" or next_id == 0:\n            break\n    return prompt\n\nprintf(generate_text('my'))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}