{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4558742,"sourceType":"datasetVersion","datasetId":2660745}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport os\nfrom tensorflow.keras import layers\nimport string\nfrom IPython.display import clear_output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:57:49.040764Z","iopub.execute_input":"2025-11-09T17:57:49.041055Z","iopub.status.idle":"2025-11-09T17:58:02.643022Z","shell.execute_reply.started":"2025-11-09T17:57:49.041030Z","shell.execute_reply":"2025-11-09T17:58:02.642373Z"}},"outputs":[{"name":"stderr","text":"2025-11-09 17:57:51.100988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762711071.288024      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762711071.340378      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"BATCH_SIZE = 128\nNUM_HEADS = 8\nNUM_BLOCKS = 2\nEMBED_DIM = 256\nDENSE_DIM = 1024\nDROPOUT_RATE = 0.3\nCHUNK_LENGTH = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.644181Z","iopub.execute_input":"2025-11-09T17:58:02.644691Z","iopub.status.idle":"2025-11-09T17:58:02.648453Z","shell.execute_reply.started":"2025-11-09T17:58:02.644671Z","shell.execute_reply":"2025-11-09T17:58:02.647611Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/the-bards-best-a-character-modeling-dataset/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.649473Z","iopub.execute_input":"2025-11-09T17:58:02.649875Z","iopub.status.idle":"2025-11-09T17:58:02.717713Z","shell.execute_reply.started":"2025-11-09T17:58:02.649849Z","shell.execute_reply":"2025-11-09T17:58:02.717172Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"text = df.values[0][0]\ntext = re.sub(r'\\s+', ' ', str(text)).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.719338Z","iopub.execute_input":"2025-11-09T17:58:02.719536Z","iopub.status.idle":"2025-11-09T17:58:02.785610Z","shell.execute_reply.started":"2025-11-09T17:58:02.719520Z","shell.execute_reply":"2025-11-09T17:58:02.785030Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import re\n\nwords = text.split()\n\n# Count unique words\nunique_words = set(words)\nprint(f\"Total words: {len(words)}\")\nprint(f\"Unique words: {len(unique_words)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.786271Z","iopub.execute_input":"2025-11-09T17:58:02.786503Z","iopub.status.idle":"2025-11-09T17:58:02.821342Z","shell.execute_reply.started":"2025-11-09T17:58:02.786486Z","shell.execute_reply":"2025-11-09T17:58:02.820738Z"}},"outputs":[{"name":"stdout","text":"Total words: 182499\nUnique words: 23841\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def chunk_text_by_words(text, max_words, stride=None):\n    words = text.split()\n    if stride is None:\n        stride = max_words // 2\n    chunks = []\n    for i in range(0, len(words) - max_words, stride):\n        chunk = ' '.join(words[i:i + max_words])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.822144Z","iopub.execute_input":"2025-11-09T17:58:02.822385Z","iopub.status.idle":"2025-11-09T17:58:02.835965Z","shell.execute_reply.started":"2025-11-09T17:58:02.822363Z","shell.execute_reply":"2025-11-09T17:58:02.835338Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"chunks = chunk_text_by_words(text, CHUNK_LENGTH+1, 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.836501Z","iopub.execute_input":"2025-11-09T17:58:02.836682Z","iopub.status.idle":"2025-11-09T17:58:02.900342Z","shell.execute_reply.started":"2025-11-09T17:58:02.836667Z","shell.execute_reply":"2025-11-09T17:58:02.899809Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(np.shape(chunks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.900964Z","iopub.execute_input":"2025-11-09T17:58:02.901208Z","iopub.status.idle":"2025-11-09T17:58:02.940241Z","shell.execute_reply.started":"2025-11-09T17:58:02.901180Z","shell.execute_reply":"2025-11-09T17:58:02.939442Z"}},"outputs":[{"name":"stdout","text":"(6075,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"strip_chars = string.punctuation + \"¿\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(\n        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n\nvocab_size = 12300\nsequence_length = CHUNK_LENGTH+1\n\nvectorizer = layers.TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n    standardize=custom_standardization\n)\n\nvectorizer.adapt(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:02.941076Z","iopub.execute_input":"2025-11-09T17:58:02.941332Z","iopub.status.idle":"2025-11-09T17:58:04.271118Z","shell.execute_reply.started":"2025-11-09T17:58:02.941285Z","shell.execute_reply":"2025-11-09T17:58:04.270351Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1762711083.675996      39 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"vocab = vectorizer.get_vocabulary()\nprint(\"Total unique tokens in vocabulary:\", len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:04.273262Z","iopub.execute_input":"2025-11-09T17:58:04.273509Z","iopub.status.idle":"2025-11-09T17:58:04.302212Z","shell.execute_reply.started":"2025-11-09T17:58:04.273493Z","shell.execute_reply":"2025-11-09T17:58:04.301600Z"}},"outputs":[{"name":"stdout","text":"Total unique tokens in vocabulary: 12074\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def make_dataset(chunks):\n    tokens = vectorizer(chunks)\n    tokens_inp = tokens[:,:CHUNK_LENGTH]\n    tokens_out = tokens[:,1:]\n    ds = tf.data.Dataset.from_tensor_slices((tokens_inp,tokens_out))\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.shuffle(1024).prefetch(16).cache()\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:04.302916Z","iopub.execute_input":"2025-11-09T17:58:04.303144Z","iopub.status.idle":"2025-11-09T17:58:04.307351Z","shell.execute_reply.started":"2025-11-09T17:58:04.303128Z","shell.execute_reply":"2025-11-09T17:58:04.306652Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ds = make_dataset(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:04.307976Z","iopub.execute_input":"2025-11-09T17:58:04.308264Z","iopub.status.idle":"2025-11-09T17:58:05.954607Z","shell.execute_reply.started":"2025-11-09T17:58:04.308247Z","shell.execute_reply":"2025-11-09T17:58:05.954024Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self, sequence_length, vocab_size, output_dim):\n        super().__init__()\n        self.positional_embedding = tf.keras.layers.Embedding(input_dim = sequence_length, output_dim = output_dim, mask_zero=False)\n        self.token_embedding = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim= output_dim, mask_zero=True)\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embedding(inputs)\n        embedded_positions = self.positional_embedding(positions)\n        return embedded_tokens + embedded_positions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:05.955313Z","iopub.execute_input":"2025-11-09T17:58:05.955540Z","iopub.status.idle":"2025-11-09T17:58:05.960985Z","shell.execute_reply.started":"2025-11-09T17:58:05.955523Z","shell.execute_reply":"2025-11-09T17:58:05.960459Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class TransformerDecoder(tf.keras.layers.Layer):\n    def __init__(self, num_heads, embed_dim, dense_dim, dropout_rate):\n        super().__init__()\n        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n                                                           key_dim=embed_dim//num_heads)\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n        self.dense_proj = tf.keras.models.Sequential([\n            tf.keras.layers.Dense(dense_dim, activation='relu'),\n            tf.keras.layers.Dense(embed_dim)\n        ])\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n    def call(self, inputs):\n        attn_out = self.attention(query=inputs,\n                            key=inputs,\n                            value=inputs,\n                            use_causal_mask=True)\n        norm1_out = self.layernorm1(attn_out+inputs)\n        drop1_out = self.dropout1(norm1_out)\n        dense_proj_out = self.dense_proj(drop1_out)\n        norm2_out = self.layernorm2(drop1_out+dense_proj_out)\n        drop2_out = self.dropout2(norm2_out)\n        return drop2_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:05.961746Z","iopub.execute_input":"2025-11-09T17:58:05.962027Z","iopub.status.idle":"2025-11-09T17:58:05.985893Z","shell.execute_reply.started":"2025-11-09T17:58:05.962009Z","shell.execute_reply":"2025-11-09T17:58:05.985173Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"inputs = tf.keras.layers.Input(shape=(None,))\nembeddings = PositionalEmbedding(sequence_length, vocab_size, EMBED_DIM)(inputs)\nx = embeddings\nfor layer in range(NUM_BLOCKS):\n    x = TransformerDecoder(NUM_HEADS, EMBED_DIM, DENSE_DIM, DROPOUT_RATE)(x)\nx = tf.keras.layers.Dropout(0.3)(x)\noutput = tf.keras.layers.Dense(vocab_size, activation='linear', kernel_initializer='glorot_uniform')(x)\ntransformer = tf.keras.models.Model(inputs, output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:05.986604Z","iopub.execute_input":"2025-11-09T17:58:05.986810Z","iopub.status.idle":"2025-11-09T17:58:07.252998Z","shell.execute_reply.started":"2025-11-09T17:58:05.986796Z","shell.execute_reply":"2025-11-09T17:58:07.252337Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"transformer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:07.253829Z","iopub.execute_input":"2025-11-09T17:58:07.254112Z","iopub.status.idle":"2025-11-09T17:58:07.271822Z","shell.execute_reply.started":"2025-11-09T17:58:07.254083Z","shell.execute_reply":"2025-11-09T17:58:07.271024Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,214,592\u001b[0m │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12300\u001b[0m)    │     \u001b[38;5;34m3,161,100\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,214,592</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12300</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,161,100</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,955,212\u001b[0m (30.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,955,212</span> (30.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,955,212\u001b[0m (30.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,955,212</span> (30.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\ndef sample_with_temperature(preds, temperature=1.0):\n    preds = np.asarray(preds).astype(\"float64\")\n    preds = np.log(preds + 1e-9) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    return np.random.choice(len(preds), p=preds)\n    \ndef generate_text(prompt, max_length=50):\n    for _ in range(max_length):\n        tokenized = vectorizer([prompt])\n        preds = transformer(tokenized)\n        next_id = tf.argmax(preds[0, -1, :]).numpy()\n        next_word = vectorizer.get_vocabulary()[next_id]\n        prompt += \" \" + next_word\n        if next_id == 0:\n            break\n    return prompt\n\nprint(generate_text('thou shall'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:07.272710Z","iopub.execute_input":"2025-11-09T17:58:07.273020Z","iopub.status.idle":"2025-11-09T17:58:13.044853Z","shell.execute_reply.started":"2025-11-09T17:58:07.272996Z","shell.execute_reply":"2025-11-09T17:58:13.044116Z"}},"outputs":[{"name":"stdout","text":"thou shall conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception conception\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"class TextGeneration(tf.keras.callbacks.Callback):\n    def __init__(self, text):\n        super().__init__()\n        self.text = text\n\n    def on_epoch_end(self, epoch, logs=None):\n        clear_output(wait=True)\n        if epoch%50 == 0:\n            output = generate_text(text)\n            print(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T17:58:13.045565Z","iopub.execute_input":"2025-11-09T17:58:13.045812Z","iopub.status.idle":"2025-11-09T17:58:13.050527Z","shell.execute_reply.started":"2025-11-09T17:58:13.045792Z","shell.execute_reply":"2025-11-09T17:58:13.049775Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nopt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n\ndef perplexity(y_true, y_pred):\n    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n    return K.exp(K.mean(cross_entropy))\ncallback = TextGeneration('to be or not to be')\ntransformer.compile(loss = loss_fn,\n                    metrics = ['accuracy', perplexity],\n                    optimizer=opt)\ntransformer.fit(ds,callbacks = [callback], epochs = 400)","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - accuracy: 0.1191 - loss: 5.5152 - perplexity: 248.6352\nEpoch 16/400\n\u001b[1m39/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.1222 - loss: 5.4639 - perplexity: 236.1647","output_type":"stream"}],"execution_count":null}]}