{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4558742,"sourceType":"datasetVersion","datasetId":2660745}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport os\nfrom tensorflow.keras import layers\nimport string","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:15.971204Z","iopub.execute_input":"2025-11-08T09:54:15.971442Z","iopub.status.idle":"2025-11-08T09:54:29.683907Z","shell.execute_reply.started":"2025-11-08T09:54:15.971426Z","shell.execute_reply":"2025-11-08T09:54:29.683141Z"}},"outputs":[{"name":"stderr","text":"2025-11-08 09:54:18.260668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762595658.440446      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762595658.493505      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"BATCH_SIZE = 128\nNUM_HEADS = 8\nNUM_BLOCKS = 6\nEMBED_DIM = 256\nDENSE_DIM = 1024\nDROPOUT_RATE = 0.1\nCHUNK_LENGTH = 150","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:29.685119Z","iopub.execute_input":"2025-11-08T09:54:29.685642Z","iopub.status.idle":"2025-11-08T09:54:29.689641Z","shell.execute_reply.started":"2025-11-08T09:54:29.685616Z","shell.execute_reply":"2025-11-08T09:54:29.688859Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/the-bards-best-a-character-modeling-dataset/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:29.690409Z","iopub.execute_input":"2025-11-08T09:54:29.690653Z","iopub.status.idle":"2025-11-08T09:54:29.932446Z","shell.execute_reply.started":"2025-11-08T09:54:29.690626Z","shell.execute_reply":"2025-11-08T09:54:29.931641Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"text = df.values[0][0]\ntext = re.sub(r'\\s+', ' ', str(text)).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:29.933984Z","iopub.execute_input":"2025-11-08T09:54:29.934220Z","iopub.status.idle":"2025-11-08T09:54:30.002679Z","shell.execute_reply.started":"2025-11-08T09:54:29.934203Z","shell.execute_reply":"2025-11-08T09:54:30.001947Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import re\n\nwords = text.split()\n\n# Count unique words\nunique_words = set(words)\nprint(f\"Total words: {len(words)}\")\nprint(f\"Unique words: {len(unique_words)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:30.003478Z","iopub.execute_input":"2025-11-08T09:54:30.003747Z","iopub.status.idle":"2025-11-08T09:54:30.039899Z","shell.execute_reply.started":"2025-11-08T09:54:30.003724Z","shell.execute_reply":"2025-11-08T09:54:30.039225Z"}},"outputs":[{"name":"stdout","text":"Total words: 182499\nUnique words: 23841\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def chunk_text_by_words(text, max_words, stride=None):\n    words = text.split()\n    if stride is None:\n        stride = max_words // 2\n    chunks = []\n    for i in range(0, len(words) - max_words, stride):\n        chunk = ' '.join(words[i:i + max_words])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:30.040592Z","iopub.execute_input":"2025-11-08T09:54:30.040803Z","iopub.status.idle":"2025-11-08T09:54:30.052492Z","shell.execute_reply.started":"2025-11-08T09:54:30.040785Z","shell.execute_reply":"2025-11-08T09:54:30.051802Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"chunks = chunk_text_by_words(text, CHUNK_LENGTH+1, 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:30.053196Z","iopub.execute_input":"2025-11-08T09:54:30.053472Z","iopub.status.idle":"2025-11-08T09:54:30.095819Z","shell.execute_reply.started":"2025-11-08T09:54:30.053456Z","shell.execute_reply":"2025-11-08T09:54:30.095254Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(np.shape(chunks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:30.096558Z","iopub.execute_input":"2025-11-08T09:54:30.096792Z","iopub.status.idle":"2025-11-08T09:54:30.124724Z","shell.execute_reply.started":"2025-11-08T09:54:30.096775Z","shell.execute_reply":"2025-11-08T09:54:30.123931Z"}},"outputs":[{"name":"stdout","text":"(4559,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"strip_chars = string.punctuation + \"¿\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(\n        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n\nvocab_size = 13000\nsequence_length = CHUNK_LENGTH+1\n\nvectorizer = layers.TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n    standardize=custom_standardization\n)\n\nvectorizer.adapt(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:30.125467Z","iopub.execute_input":"2025-11-08T09:54:30.125665Z","iopub.status.idle":"2025-11-08T09:54:31.163181Z","shell.execute_reply.started":"2025-11-08T09:54:30.125650Z","shell.execute_reply":"2025-11-08T09:54:31.162575Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1762595670.819286      39 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"vocab = vectorizer.get_vocabulary()\nprint(\"Total unique tokens in vocabulary:\", len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:31.165476Z","iopub.execute_input":"2025-11-08T09:54:31.165827Z","iopub.status.idle":"2025-11-08T09:54:31.194229Z","shell.execute_reply.started":"2025-11-08T09:54:31.165810Z","shell.execute_reply":"2025-11-08T09:54:31.193668Z"}},"outputs":[{"name":"stdout","text":"Total unique tokens in vocabulary: 12074\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def make_dataset(chunks):\n    tokens = vectorizer(chunks)\n    tokens_inp = tokens[:,:CHUNK_LENGTH]\n    tokens_out = tokens[:,1:]\n    ds = tf.data.Dataset.from_tensor_slices((tokens_inp,tokens_out))\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.shuffle(1024).prefetch(16).cache()\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:31.194827Z","iopub.execute_input":"2025-11-08T09:54:31.195038Z","iopub.status.idle":"2025-11-08T09:54:31.199139Z","shell.execute_reply.started":"2025-11-08T09:54:31.195023Z","shell.execute_reply":"2025-11-08T09:54:31.198544Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ds = make_dataset(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:31.199698Z","iopub.execute_input":"2025-11-08T09:54:31.199924Z","iopub.status.idle":"2025-11-08T09:54:32.544901Z","shell.execute_reply.started":"2025-11-08T09:54:31.199898Z","shell.execute_reply":"2025-11-08T09:54:32.544325Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self, sequence_length, vocab_size, output_dim):\n        super().__init__()\n        self.positional_embedding = tf.keras.layers.Embedding(input_dim = sequence_length, output_dim = output_dim, mask_zero=False)\n        self.token_embedding = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim= output_dim, mask_zero=True)\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embedding(inputs)\n        embedded_positions = self.positional_embedding(positions)\n        return embedded_tokens + embedded_positions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:32.545791Z","iopub.execute_input":"2025-11-08T09:54:32.546039Z","iopub.status.idle":"2025-11-08T09:54:32.551268Z","shell.execute_reply.started":"2025-11-08T09:54:32.546012Z","shell.execute_reply":"2025-11-08T09:54:32.550557Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class TransformerDecoder(tf.keras.layers.Layer):\n    def __init__(self, num_heads, embed_dim, dense_dim, dropout_rate):\n        super().__init__()\n        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n                                                           key_dim=embed_dim//num_heads)\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n        self.dense_proj = tf.keras.models.Sequential([\n            tf.keras.layers.Dense(dense_dim, activation='gelu'),\n            tf.keras.layers.Dense(embed_dim)\n        ])\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n    def call(self, inputs):\n        attn_out = self.attention(query=inputs,\n                            key=inputs,\n                            value=inputs,\n                            use_causal_mask=True)\n        norm1_out = self.layernorm1(attn_out+inputs)\n        drop1_out = self.dropout1(norm1_out)\n        dense_proj_out = self.dense_proj(drop1_out)\n        norm2_out = self.layernorm2(drop1_out+dense_proj_out)\n        drop2_out = self.dropout2(norm2_out)\n        return drop2_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:32.552080Z","iopub.execute_input":"2025-11-08T09:54:32.552335Z","iopub.status.idle":"2025-11-08T09:54:32.570773Z","shell.execute_reply.started":"2025-11-08T09:54:32.552311Z","shell.execute_reply":"2025-11-08T09:54:32.570044Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"inputs = tf.keras.layers.Input(shape=(None,))\nembeddings = PositionalEmbedding(sequence_length, vocab_size, EMBED_DIM)(inputs)\nx = embeddings\nfor layer in range(NUM_BLOCKS):\n    x = TransformerDecoder(NUM_HEADS, EMBED_DIM, DENSE_DIM, DROPOUT_RATE)(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutput = tf.keras.layers.Dense(vocab_size)(x)\ntransformer = tf.keras.models.Model(inputs, output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:32.571450Z","iopub.execute_input":"2025-11-08T09:54:32.571686Z","iopub.status.idle":"2025-11-08T09:54:34.829790Z","shell.execute_reply.started":"2025-11-08T09:54:32.571667Z","shell.execute_reply":"2025-11-08T09:54:34.829230Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"transformer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:34.830473Z","iopub.execute_input":"2025-11-08T09:54:34.830709Z","iopub.status.idle":"2025-11-08T09:54:34.852866Z","shell.execute_reply.started":"2025-11-08T09:54:34.830684Z","shell.execute_reply":"2025-11-08T09:54:34.852366Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,366,656\u001b[0m │\n│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13000\u001b[0m)    │     \u001b[38;5;34m3,341,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,366,656</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,446,216\u001b[0m (43.66 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,446,216</span> (43.66 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,446,216\u001b[0m (43.66 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,446,216</span> (43.66 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\ndef perplexity(y_true, y_pred):\n    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n    return K.exp(K.mean(cross_entropy))\n\ntransformer.compile(loss = loss_fn,\n                    metrics = ['accuracy', perplexity],\n                    optimizer=opt)\ntransformer.fit(ds, epochs = 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:54:34.853474Z","iopub.execute_input":"2025-11-08T09:54:34.853872Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1762595698.008692      99 service.cc:148] XLA service 0x78b48c023260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1762595698.009619      99 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nW0000 00:00:1762595699.280774      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1762595699.280895      99 assert_op.cc:38] Ignoring Assert operator SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nI0000 00:00:1762595700.291747      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1762595713.615183      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m13/36\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.0169 - loss: 8.8354 - perplexity: 8188.5547","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1762595717.369800      98 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1762595717.369864      98 assert_op.cc:38] Ignoring Assert operator SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 568ms/step - accuracy: 0.0223 - loss: 8.0754 - perplexity: 4949.9932\nEpoch 2/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - accuracy: 0.0291 - loss: 6.8148 - perplexity: 913.4657\nEpoch 3/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0299 - loss: 6.8017 - perplexity: 901.4036\nEpoch 4/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0300 - loss: 6.7962 - perplexity: 896.3240\nEpoch 5/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0301 - loss: 6.7945 - perplexity: 894.7186\nEpoch 6/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0296 - loss: 6.7915 - perplexity: 891.9363\nEpoch 7/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0298 - loss: 6.7896 - perplexity: 890.3498\nEpoch 8/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0299 - loss: 6.7879 - perplexity: 888.7051\nEpoch 9/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0299 - loss: 6.7870 - perplexity: 887.9250\nEpoch 10/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0301 - loss: 6.7862 - perplexity: 887.2607\nEpoch 11/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0298 - loss: 6.7858 - perplexity: 886.8057\nEpoch 12/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0298 - loss: 6.7855 - perplexity: 886.5278\nEpoch 13/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - accuracy: 0.0307 - loss: 6.7857 - perplexity: 886.6474\nEpoch 14/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0308 - loss: 6.7864 - perplexity: 887.1806\nEpoch 15/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0311 - loss: 6.7864 - perplexity: 887.1588\nEpoch 16/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0310 - loss: 6.7845 - perplexity: 885.6138\nEpoch 17/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0305 - loss: 6.7828 - perplexity: 884.2548\nEpoch 18/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0302 - loss: 6.7793 - perplexity: 881.2101\nEpoch 19/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0301 - loss: 6.7774 - perplexity: 879.4828\nEpoch 20/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0303 - loss: 6.7763 - perplexity: 878.5728\nEpoch 21/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0300 - loss: 6.7747 - perplexity: 877.0685\nEpoch 22/100\n\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - accuracy: 0.0301 - loss: 6.7736 - perplexity: 876.1370\nEpoch 23/100\n\u001b[1m15/36\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - accuracy: 0.0297 - loss: 6.7612 - perplexity: 865.4482","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def generate_text(prompt, max_length=50):\n    for _ in range(max_length):\n        tokenized = vectorizer([prompt])\n        preds = transformer(tokenized)\n        next_id = tf.argmax(preds[0, -1, :]).numpy()\n        next_word = vectorizer.get_vocabulary()[next_id]\n        prompt += \" \" + next_word\n        if next_id == 0:\n            break\n    return prompt\n\nprint(generate_text(\"my\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}